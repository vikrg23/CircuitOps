{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPDX-FileCopyrightText: Copyright (c) 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
    "\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "#\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "\n",
    "# you may not use this file except in compliance with the License.\n",
    "\n",
    "# You may obtain a copy of the License at\n",
    "\n",
    "#\n",
    "\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "#\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "\n",
    "# See the License for the specific language governing permissions and\n",
    "\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/yba/miniconda3/envs/andlai_dgl/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "### This notebook reads the dgl graph and does preprocessing according to data_graph.py for the model to read\n",
    "import os, sys\n",
    "ROOT_DIR = '/raid/andlai/2024_ICCAD_Contest_Gate_Sizing_Benchmark'\n",
    "sys.path.append(ROOT_DIR)\n",
    "import time\n",
    "\n",
    "import pickle as pk\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import dgl\n",
    "import networkx as nx\n",
    "# import graph_tool as gt\n",
    "# from graph_tool.all import *\n",
    "\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 NV_NVDLA_partition_m 83671 80415 54280 55966 86\n",
      "1 NV_NVDLA_partition_m 265 30 15 249 16\n",
      "2 NV_NVDLA_partition_m 458 390 264 298 16\n",
      "0 NV_NVDLA_partition_p 273679 234273 171386 193361 82\n",
      "1 NV_NVDLA_partition_p 5139 396 198 4940 26\n",
      "0 ariane136 499589 454282 329085 352154 190\n",
      "1 ariane136 17777 1167 583 17193 28\n",
      "2 ariane136 3595 313 156 3438 26\n",
      "0 mempool_tile_wrap 657377 617005 447458 468169 184\n",
      "1 mempool_tile_wrap 9077 559 279 8797 22\n",
      "2 mempool_tile_wrap 4163 51 33 4129 6\n",
      "3 mempool_tile_wrap 903 102 67 835 8\n",
      "4 mempool_tile_wrap 903 102 67 835 8\n"
     ]
    }
   ],
   "source": [
    "## load all datasets in design_names = ['NV_NVDLA_partition_m', 'NV_NVDLA_partition_p', 'ariane136', 'mempool_tile_wrap']\n",
    "design_names = ['NV_NVDLA_partition_m', 'NV_NVDLA_partition_p', 'ariane136', 'mempool_tile_wrap']\n",
    "dataset_dir = '0709_v1'\n",
    "\n",
    "# read all the graph for all the designs\n",
    "gs = {}\n",
    "for design_name in design_names:\n",
    "    design_dir = f'{ROOT_DIR}/datasets/{dataset_dir}/{design_name}'\n",
    "    gs[design_name] = dgl.load_graphs(f'{design_dir}/graph.dgl')[0]\n",
    "\n",
    "# identical function taken from data_graph.py\n",
    "def gen_topo(g_hetero):\n",
    "    torch.cuda.synchronize()\n",
    "    time_s = time.time()\n",
    "    na, nb = g_hetero.edges(etype='net_out', form='uv')\n",
    "    ca, cb = g_hetero.edges(etype='cell_out', form='uv')\n",
    "    g = dgl.graph((torch.cat([na, ca]).cpu(), torch.cat([nb, cb]).cpu()))\n",
    "    topo = dgl.topological_nodes_generator(g)\n",
    "\n",
    "    ### inspect the topography!\n",
    "    g.ndata['fanout'] = g_hetero.ndata['nf'][:, 1].cpu()\n",
    "    for li, nodes in enumerate(topo):\n",
    "        # print(f'level {li}, # nodes = {len(nodes)}')\n",
    "        # print(g.ndata['fanout'][nodes.numpy()])\n",
    "        assert (li % 2 == 0 and (g.ndata['fanout'][nodes] == 0).sum() == 0) or (li % 2 == 1 and (g.ndata['fanout'][nodes] == 1).sum() == 0)\n",
    "\n",
    "    assert len(topo) % 2 == 0\n",
    "\n",
    "    ret = [t.cuda() for t in topo]\n",
    "    torch.cuda.synchronize()\n",
    "    time_e = time.time()\n",
    "    return ret, time_e - time_s\n",
    "\n",
    "data = {}\n",
    "# data preprocessing\n",
    "for design_name, des_gs in gs.items():\n",
    "    for gi, g in enumerate(des_gs):\n",
    "        g.nodes['node'].data['nf'] = g.nodes['node'].data['nf'].type(torch.float32)\n",
    "        g.edges['cell_out'].data['ef'] = g.edges['cell_out'].data['ef'].type(torch.float32)\n",
    "        g.edges['net_out'].data['ef'] = g.edges['net_out'].data['ef'].type(torch.float32)\n",
    "        g.edges['net_in'].data['ef'] = g.edges['net_in'].data['ef'].type(torch.float32)\n",
    "        g.ndata['n_tsrf'] = torch.stack([g.ndata['n_tran'], g.ndata['n_slack'], g.ndata['n_risearr'], g.ndata['n_fallarr']], axis=1).type(torch.float32)\n",
    "\n",
    "        g = g.to('cuda')\n",
    "\n",
    "        # print(f'{design_name}, {gi+1}/{len(des_gs)}')\n",
    "        topo, topo_time = gen_topo(g)\n",
    "\n",
    "        ts = {'input_nodes': (g.ndata['nf'][:, 1] < 0.5).nonzero().flatten().type(torch.int32),\n",
    "            'output_nodes': (g.ndata['nf'][:, 1] > 0.5).nonzero().flatten().type(torch.int32),\n",
    "            'output_nodes_nonpi': torch.logical_and(g.ndata['nf'][:, 1] > 0.5, g.ndata['nf'][:, 0] < 0.5).nonzero().flatten().type(torch.int32),\n",
    "            'pi_nodes': torch.logical_and(g.ndata['nf'][:, 1] > 0.5, g.ndata['nf'][:, 0] > 0.5).nonzero().flatten().type(torch.int32),\n",
    "            'po_nodes': torch.logical_and(g.ndata['nf'][:, 1] < 0.5, g.ndata['nf'][:, 0] > 0.5).nonzero().flatten().type(torch.int32),\n",
    "            'endpoints': (g.ndata['n_is_end'] > 0.5).nonzero().flatten().type(torch.long),\n",
    "            'topo': topo,\n",
    "            'topo_time': topo_time}\n",
    "\n",
    "        # set nans to zero\n",
    "        g.ndata['nf'][torch.isnan(g.ndata['nf'])] = 0\n",
    "        g.ndata['n_tsrf'][torch.isnan(g.ndata['n_tsrf'])] = 0\n",
    "\n",
    "        # normalize\n",
    "        g.ndata['nf'][:,2:] = (g.ndata['nf'][:,2:] - g.ndata['nf'][:,2:].mean(axis=0)) / g.ndata['nf'][:,2:].std(axis=0)\n",
    "        g.ndata['n_tsrf'] = (g.ndata['n_tsrf'] - g.ndata['n_tsrf'].mean(axis=0)) / g.ndata['n_tsrf'].std(axis=0)\n",
    "        \n",
    "        data[f'{design_name}_{gi}'] = g, ts\n",
    "\n",
    "        # just for report\n",
    "        print(gi, design_name, len(g.ndata['nf']), g.ndata['train_mask'].sum().item(), len(g.edata['ef'][('node', 'cell_out', 'node')]), len(g.edata['ef'][('node', 'net_out', 'node')]), len(topo))\n",
    "\n",
    "data_train = {k: t for k, t in data.items()}\n",
    "data_test = data_train # set identical --- just testing if prediction training works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[node data] ( = dstdata)\n",
      "_ID                    torch.Size([903])\n",
      "train_mask             torch.Size([903])\n",
      "n_is_end               torch.Size([903])\n",
      "n_fallarr              torch.Size([903])\n",
      "n_slack                torch.Size([903])\n",
      "n_risearr              torch.Size([903])\n",
      "n_tran                 torch.Size([903])\n",
      "nf                     torch.Size([903, 8])\n",
      "  is_prim IO           torch.Size([903, 1])\n",
      "  fanout(1) or in(0)   torch.Size([903, 1])\n",
      "  dis to tlrb          torch.Size([903, 4])\n",
      "  RF cap               torch.Size([903, 2])\n",
      "n_tsrf                 torch.Size([903, 4])\n",
      "\n",
      "[edge data]\n",
      "_ID:\n",
      "  ('node', 'cell_out', 'node')   torch.Size([67])\n",
      "  ('node', 'net_in', 'node')     torch.Size([835])\n",
      "  ('node', 'net_out', 'node')    torch.Size([835])\n",
      "ef:\n",
      "  ('node', 'cell_out', 'node')   torch.Size([67, 256])\n",
      "  ('node', 'net_in', 'node')     torch.Size([835, 5])\n",
      "  ('node', 'net_out', 'node')    torch.Size([835, 5])\n"
     ]
    }
   ],
   "source": [
    "print('[node data] ( = dstdata)')\n",
    "for nkey, ndat in g.ndata.items():\n",
    "    assert type(ndat) == torch.Tensor, 'Type must be torch.Tensor'\n",
    "    print(f'{nkey:22s} {ndat.shape}')\n",
    "    if nkey == 'nf':\n",
    "        nf = ndat\n",
    "        for fkey, frange in [('is_prim IO', [0,1]), ('fanout(1) or in(0)', [1,2]), ('dis to tlrb', [2,6]), ('RF cap', [6,8])]:\n",
    "            print(f'  {fkey:20s} {ndat[:, frange[0]:frange[1]].shape}')\n",
    "print()\n",
    "\n",
    "print('[edge data]')\n",
    "for ekey, edat in g.edata.items():\n",
    "    assert type(edat) == dict, 'Type must be dict'\n",
    "    print(f'{ekey}:')\n",
    "    for edat_key, edat_dat in edat.items():\n",
    "        print(f'  {f\"{edat_key}\":30s} {edat_dat.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/data_train.pk', 'wb') as pkf:\n",
    "    pk.dump(data_train, pkf)\n",
    "with open('data/data_test.pk', 'wb') as pkf:\n",
    "    pk.dump(data_test, pkf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
